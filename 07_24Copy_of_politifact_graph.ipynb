{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of politifact_graph.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verma-saloni/Articles/blob/master/07_24Copy_of_politifact_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpTeMbYZwmf7"
      },
      "outputs": [],
      "source": [
        "!pip -qq install jsonlines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "from pathlib import Path\n",
        "base_dir = Path(\"/gdrive/MyDrive/ResearchFND\")\n",
        "assert base_dir.exists()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxNEaltli8H_",
        "outputId": "2ef65b7f-2b2e-42e8-aad8-8718e9d4f848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Twt user graphs"
      ],
      "metadata": {
        "id": "60XHa2QqsF2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import jsonlines"
      ],
      "metadata": {
        "id": "7lCdLfhNsEyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = nx.DiGraph()"
      ],
      "metadata": {
        "id": "Q0vjdfpgsQJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open(base_dir/\"followers.jsonl\") as reader:\n",
        "    for line in reader:\n",
        "        v = line[\"user_id\"]\n",
        "        for u in line[\"followers\"]:\n",
        "            graph.add_edge(u, v)"
      ],
      "metadata": {
        "id": "KnrRSt2Qsb6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open(base_dir/\"following.jsonl\") as reader:\n",
        "    for line in reader:\n",
        "        u = line[\"user_id\"]\n",
        "        for v in line[\"following\"]:\n",
        "            graph.add_edge(u, v)"
      ],
      "metadata": {
        "id": "Y7DLQ78as4pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph.number_of_nodes(), graph.number_of_edges()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCN3DvNQtiJR",
        "outputId": "b4f0f440-36e5-4418-f2c4-c06728e8c8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31792, 48408)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "followed = [n for n in graph.nodes if graph.in_degree(n)>2]\n",
        "len(followed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-x18_ZZulOd",
        "outputId": "3e4fd2ed-76e7-4080-8b40-912de5acedea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "444"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "sample_nodes = random.sample(followed, 12)\n",
        "sg = graph.edge_subgraph(graph.in_edges(sample_nodes))\n",
        "sg.number_of_nodes(), sg.number_of_edges()"
      ],
      "metadata": {
        "id": "ytEH363Cu7e_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc1b4d5-1f1f-479c-ff5a-21ea832bbfed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nx.draw(sg, node_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "yYc34e6ts7PN",
        "outputId": "0cbcf5a1-1ffa-4dd0-cd68-8969587f2f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node embeddings"
      ],
      "metadata": {
        "id": "qbRXmgXCwoNj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28effea1-9db8-4c0f-b037-3df8dadbea17",
        "outputId": "18bb945e-871c-4dea-dd0a-ccdbb85fe832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for csrgraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nodevectors (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq csrgraph nodevectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csrgraph as cg\n",
        "from nodevectors import Node2Vec"
      ],
      "metadata": {
        "id": "qvL85vFzr2XK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### user vectors"
      ],
      "metadata": {
        "id": "odOQGulI-EeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n2v = Node2Vec(n_components=128, walklen=10, epochs=10)"
      ],
      "metadata": {
        "id": "RvlSsu6jvXS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n2v.fit(graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHoiGFydwFMk",
        "outputId": "af696748-7047-4823-c293-acffb1c3f7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making walks... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done, T=5.25\n",
            "Mapping Walk Names... Done, T=7.71\n",
            "Training W2V... WARNING: gensim word2vec version is unoptimizedTry version 3.6 if on windows, versions 3.7 and 3.8 have had issues\n",
            "Done, T=84.63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n2v.predict(followed[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RicJpnXuwJhE",
        "outputId": "df782e17-8f72-4e30-9eb1-ea08fb0437f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.3675863 ,  0.1282412 ,  0.22299092, -0.31979853,  0.18588693,\n",
              "       -0.11166151, -0.25063002, -0.00243194,  0.3993893 ,  0.2265691 ,\n",
              "        0.24865997, -0.00837706, -0.07028485, -0.20618919,  0.23557512,\n",
              "       -0.14061683,  0.30435127, -0.39891508,  0.06668442, -0.33265588,\n",
              "       -0.02163144, -0.36777756, -0.16099092,  0.21908268, -0.19462305,\n",
              "       -0.40506038, -0.25495267, -0.45383984, -0.5653268 ,  0.35322955,\n",
              "       -0.5327221 ,  0.52026945,  0.32708022,  0.0113182 ,  0.40652302,\n",
              "        0.21851438,  0.10024845,  0.35892075,  0.40906376,  0.04410933,\n",
              "       -0.50577044,  0.21270105,  0.5493385 ,  0.15493374,  0.09996232,\n",
              "       -0.37725475, -0.37640077,  0.2239793 ,  0.17491885, -0.2525284 ,\n",
              "        0.16396652,  0.25392124,  0.3824317 , -0.03385516,  0.4343061 ,\n",
              "       -0.01122301,  0.03740161,  0.06381975, -0.02905279, -0.05415915,\n",
              "       -0.09567568, -0.35780594,  0.2964456 , -0.5187444 ,  0.10663714,\n",
              "       -0.30514914,  0.13067374, -0.05766976, -0.25125933,  0.02838036,\n",
              "       -0.10923844,  0.3680409 ,  0.1466139 , -0.29836094,  0.4735993 ,\n",
              "        0.41329947, -0.26242357, -0.5369673 , -0.43316695, -0.168669  ,\n",
              "        0.18525039, -0.14915812,  0.4306212 , -0.1937244 ,  0.535601  ,\n",
              "       -0.06732793, -0.42905512, -0.11690461,  0.29821655, -0.44861498,\n",
              "        0.20499462, -0.34825817,  0.07389084, -0.3002827 , -0.31174114,\n",
              "        0.05700825,  0.56036174,  0.2569448 ,  0.2916066 , -0.18752065,\n",
              "       -0.42436475,  0.2378338 , -0.4374494 , -0.32618782, -0.21294492,\n",
              "        0.3716916 , -0.12359514,  0.25273126, -0.5215603 ,  0.18840842,\n",
              "       -0.20114021, -0.3934462 ,  0.49193785,  0.04989393,  0.12659249,\n",
              "        0.12628333, -0.33194947, -0.38520122, -0.4027925 , -0.27302036,\n",
              "        0.11351606,  0.12338854, -0.22894095, -0.24686773,  0.19909653,\n",
              "        0.02797645,  0.00258626, -0.26178077], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## user-article graph"
      ],
      "metadata": {
        "id": "NHdG78wwVumY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast"
      ],
      "metadata": {
        "id": "7tPiW_FBWO8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(base_dir/'politifact_agg.csv', index_col=0)\n",
        "df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "0BsiweMKV3Kt",
        "outputId": "c2081efb-8798-419c-fdb1-3753c3ad4b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title text tweets  \\\n",
              "0   Actress Emma Stone For the first time in his...  NaN     []   \n",
              "1   Breaking President Trump makes English the of...  NaN     []   \n",
              "\n",
              "                                            retweets label  url tweet_ids  \\\n",
              "0  ['1020554564334964741', '1020817527046197248',...  fake  NaN        []   \n",
              "1                                                 []  fake  NaN        []   \n",
              "\n",
              "   num_retweets  log_num_retweets  num_tweets  log_num_tweets  \n",
              "0          2911          7.976595           0             0.0  \n",
              "1             0          0.000000           0             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c002453-36bc-45de-be89-5925a63ed715\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>tweets</th>\n",
              "      <th>retweets</th>\n",
              "      <th>label</th>\n",
              "      <th>url</th>\n",
              "      <th>tweet_ids</th>\n",
              "      <th>num_retweets</th>\n",
              "      <th>log_num_retweets</th>\n",
              "      <th>num_tweets</th>\n",
              "      <th>log_num_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Actress Emma Stone For the first time in his...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>['1020554564334964741', '1020817527046197248',...</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>2911</td>\n",
              "      <td>7.976595</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Breaking President Trump makes English the of...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>fake</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c002453-36bc-45de-be89-5925a63ed715')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c002453-36bc-45de-be89-5925a63ed715 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c002453-36bc-45de-be89-5925a63ed715');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweets'] = df.tweets.map(ast.literal_eval)"
      ],
      "metadata": {
        "id": "cruZFCpNWRLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df[df.tweets.map(len) > 0]"
      ],
      "metadata": {
        "id": "FmEDMzaPWrT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_tweeted = df.tweets.map(lambda x: [int(e['user_id']) for e in x])"
      ],
      "metadata": {
        "id": "wH5i98HOWz1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(users_tweeted), sum(users_tweeted.map(len) > 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exnDy-5ud_uJ",
        "outputId": "8769dfed-4e4a-46ce-aa33-1bba9afcb1e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(894, 149)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_tweeted[users_tweeted.map(len) > 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RfPGb15XgKE",
        "outputId": "2b74b633-6dc4-405d-e2c0-87fa24d6b183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8      [1191949489, 51600575, 2984014208, 15496777, 4...\n",
              "10     [24636033, 22473015, 129262130, 181289232, 181...\n",
              "11     [490975378, 116344653, 79423345, 53347857, 842...\n",
              "12     [586165566, 393939273, 891366735064039425, 991...\n",
              "14     [886818711105138688, 172947702, 993606350, 428...\n",
              "                             ...                        \n",
              "875    [14378429, 3187248602, 484966779, 950864702669...\n",
              "880    [2236833270, 22250210, 54835665, 347507710, 45...\n",
              "884    [2582795785, 736847516537368576, 7769521655752...\n",
              "887    [348175292, 810185480469880833, 84976273735388...\n",
              "893    [747513995096055808, 19086760, 27623387, 12455...\n",
              "Name: tweets, Length: 149, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_users = set()\n",
        "for e in users_tweeted:\n",
        "    unique_users.update(set(e))\n",
        "\n",
        "len(unique_users)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUjaXHhFYIMc",
        "outputId": "e52aaed2-9f68-4fef-acab-53ada5c35d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40723"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(unique_users)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHgKrYoEYTZQ",
        "outputId": "fabb6bc1-6e47-4785-d6dd-922ecb441221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1688"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for u in unique_users:\n",
        "    if u in graph:\n",
        "        i += 1\n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF3sOiF_bcip",
        "outputId": "a7453b0b-b044-4a12-d27b-0afe53706dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_retweeted = df.retweets.map(lambda x: [int(e) for e in ast.literal_eval(x)])"
      ],
      "metadata": {
        "id": "NPSabn0Je819"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in users_retweeted:\n",
        "    unique_users.update(set(e))\n",
        "\n",
        "len(unique_users)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UevgMKgIfeqt",
        "outputId": "400fcb74-1851-4474-a42c-f8206b507df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "595543"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for u in unique_users:\n",
        "    if u in graph:\n",
        "        i += 1\n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQttmXbOfwz3",
        "outputId": "d5d32941-f89a-418e-fad1-984745863f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, l in users_tweeted.iteritems():\n",
        "    if not len(l):\n",
        "        continue\n",
        "    a_node = f\"a{i}\"\n",
        "    graph.add_edges_from([(a_node, u_node) for u_node in l if u_node in graph])\n",
        "\n",
        "graph.number_of_nodes(), graph.number_of_edges()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TacXl683Z-BC",
        "outputId": "9c6ffc5f-216e-49c2-e330-f35668773c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31896, 49576)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = users_tweeted.map(len)\n",
        "tmp.min(), tmp.mean(), tmp.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lnh-YSHaYlH",
        "outputId": "ee149d97-ddb4-44c0-ab43-60a1c645b8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 70.42953020134229, 21984)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN"
      ],
      "metadata": {
        "id": "gI6AtSffmcqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data"
      ],
      "metadata": {
        "id": "FfaOg08xmfEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "xjD3rF-MmwKa",
        "outputId": "5228d3b5-e600-423c-cb01-9fa4cd903d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl\n",
            "  Downloading dgl-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (6.2 MB)\n",
            "\u001b[K     || 6.2 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dgl) (4.64.0)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     || 281 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.7.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Installing collected packages: psutil, dgl\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed dgl-0.9.0 psutil-5.9.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp52MLR1mdxA",
        "outputId": "cc330e1b-98b8-4e70-870d-70300830c133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u2i = {}\n",
        "\n",
        "follow_src = []\n",
        "follow_dst = []\n",
        "with jsonlines.open(base_dir/\"followers.jsonl\") as reader:\n",
        "    for line in reader:\n",
        "        v = line[\"user_id\"]\n",
        "        if v not in u2i:\n",
        "            u2i[v] = len(u2i)\n",
        "        for u in line[\"followers\"]:\n",
        "            if u not in u2i:\n",
        "                u2i[u] = len(u2i)\n",
        "            follow_src.append(u2i[u])\n",
        "            follow_dst.append(u2i[v])"
      ],
      "metadata": {
        "id": "h3XOCaEwoMvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open(base_dir/\"following.jsonl\") as reader:\n",
        "    for line in reader:\n",
        "        u = line[\"user_id\"]\n",
        "        if u not in u2i:\n",
        "            u2i[u] = len(u2i)\n",
        "        for v in line[\"following\"]:\n",
        "            if v not in u2i:\n",
        "                u2i[v] = len(u2i)\n",
        "            follow_src.append(u2i[u])\n",
        "            follow_dst.append(u2i[v])"
      ],
      "metadata": {
        "id": "sWJFoJ_4oMvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_src = []\n",
        "tweet_dst = []\n",
        "\n",
        "for v, l in users_tweeted.iteritems():\n",
        "    if not len(l):\n",
        "        continue\n",
        "    for u in l:\n",
        "        if u in u2i:\n",
        "            tweet_src.append(u2i[u])\n",
        "            tweet_dst.append(v)"
      ],
      "metadata": {
        "id": "DWM9MEXDpiyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_embs = np.load(base_dir/'sbert_fulltext_embeddings.npy')\n",
        "text_embs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxkWUv799WnY",
        "outputId": "83209797-5819-46c3-c541-f0a59b71fe35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(894, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_embs= pd.read_csv('updatedEmbs.csv')\n",
        "final_embs= final_embs.drop('Unnamed: 0',axis=1)\n",
        "final_embs = final_embs.reset_index(drop=True)\n",
        "print(final_embs)\n",
        "\n",
        "text_embs= final_embs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT3XHzLyHf_k",
        "outputId": "9292f7c6-88f2-4f4b-b9cf-441c48b0e2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             0          1        0.1        1.1     0.1.1     1.1.1         2  \\\n",
            "0     2.304911  -2.593269   2.804225  -2.284072 -0.005148  0.119410 -0.002614   \n",
            "1     3.648591  -3.850141   4.940054  -4.574084  0.003329  0.073702  0.013172   \n",
            "2     3.361981  -3.548838   2.995287  -2.522358 -0.002448  0.007355  0.009388   \n",
            "3     2.504427  -3.042817   2.997637  -2.761740  0.088057  0.066452  0.037585   \n",
            "4    -4.903805   5.116224  -3.947925   4.467043 -0.005155  0.097338  0.004930   \n",
            "..         ...        ...        ...        ...       ...       ...       ...   \n",
            "889   4.191693  -4.286413   3.577387  -3.207390 -0.023371  0.092738  0.007361   \n",
            "890   3.160366  -3.602673   3.074439  -2.675382  0.023739  0.075171  0.006070   \n",
            "891  -3.076209   3.358016  -1.825760   2.256844 -0.010513  0.048753  0.028684   \n",
            "892   2.994384  -2.754756   3.456599  -3.052860  0.024099  0.128845 -0.017875   \n",
            "893 -34.898632  34.124060 -62.266293  62.019722  0.010217  0.085520  0.038988   \n",
            "\n",
            "            3         4         5  ...       758       759       760  \\\n",
            "0    0.019297  0.081178  0.025727  ...  0.012692  0.059102  0.000541   \n",
            "1   -0.012052 -0.019934  0.022083  ... -0.017646  0.061697  0.007149   \n",
            "2    0.053711 -0.023324  0.000288  ...  0.039987  0.010057 -0.038091   \n",
            "3   -0.013241  0.014072  0.023239  ... -0.070302 -0.045334  0.016006   \n",
            "4   -0.013134 -0.012577 -0.004790  ...  0.007845  0.069599 -0.017022   \n",
            "..        ...       ...       ...  ...       ...       ...       ...   \n",
            "889 -0.019501  0.010361  0.021039  ... -0.026921  0.033994  0.025864   \n",
            "890 -0.067172  0.016169  0.024615  ...  0.092023 -0.017697  0.014944   \n",
            "891  0.000889 -0.043573  0.023155  ... -0.050173  0.037019 -0.048023   \n",
            "892  0.012632 -0.030615 -0.001186  ... -0.008388  0.008983 -0.058522   \n",
            "893 -0.019996  0.000146  0.023523  ...  0.025953  0.049041 -0.015561   \n",
            "\n",
            "          761       762       763       764       765       766       767  \n",
            "0    0.006523 -0.018735  0.046029 -0.031323  0.021993 -0.059348  0.010890  \n",
            "1    0.000070  0.010949  0.033709 -0.033934 -0.006214 -0.046594 -0.020140  \n",
            "2   -0.033632 -0.018176 -0.017782  0.028502  0.009641 -0.035604 -0.009934  \n",
            "3    0.018444  0.056975  0.053900  0.043913  0.003843 -0.038083  0.000696  \n",
            "4    0.010712 -0.014984 -0.001413 -0.022211 -0.025620  0.007522 -0.037539  \n",
            "..        ...       ...       ...       ...       ...       ...       ...  \n",
            "889 -0.034472  0.024374 -0.022076 -0.001890  0.006269 -0.019845  0.016206  \n",
            "890 -0.065511  0.016395  0.007684 -0.016207 -0.008501  0.049251 -0.022232  \n",
            "891  0.000220 -0.033158  0.075531  0.064022 -0.000590 -0.031904 -0.002240  \n",
            "892 -0.008533 -0.016264  0.003724 -0.005826 -0.020846 -0.027097 -0.008377  \n",
            "893 -0.064802  0.025398  0.007854 -0.010056  0.026847 -0.055978 -0.010197  \n",
            "\n",
            "[894 rows x 772 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "follow_src = torch.tensor(follow_src)\n",
        "follow_dst = torch.tensor(follow_dst)\n",
        "tweet_src = torch.tensor(tweet_src)\n",
        "tweet_dst = torch.tensor(tweet_dst)\n",
        "\n",
        "hetero_graph = dgl.heterograph({\n",
        "    ('user', 'follow', 'user'): (follow_src, follow_dst),\n",
        "    ('user', 'followed-by', 'user'): (follow_dst, follow_src),\n",
        "    ('user', 'tweet', 'article'): (tweet_src, tweet_dst),\n",
        "    ('article', 'tweeted-by', 'user'): (tweet_dst, tweet_src)})\n",
        "\n",
        "hetero_graph.nodes['user'].data['feat'] = torch.arange(hetero_graph.num_nodes('user'))  \n",
        "hetero_graph.nodes['article'].data['feat'] = torch.tensor(text_embs.values.tolist())\n",
        "hetero_graph.nodes['article'].data['label'] = torch.tensor((df.label==\"real\").to_numpy()).long()"
      ],
      "metadata": {
        "id": "ui3y2a80muWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0731cfcb-8362-4ccd-ca0e-7510d0e6e1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hetero_graph.number_of_nodes(ntype='article'), hetero_graph.number_of_nodes(ntype='user')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcmqOPpJsK6Z",
        "outputId": "2e59b447-b5f4-41ff-fb48-e480af93ed67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(894, 31792)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hetero_graph.nodes['article'].data['train_mask'] = torch.zeros(hetero_graph.number_of_nodes(ntype='article'), dtype=torch.bool).bernoulli(0.8)"
      ],
      "metadata": {
        "id": "2LboKsvbsJAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "a_NnqbhIvgQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_dict(d):\n",
        "    for k, v in d.items():\n",
        "        d[k] = v.flatten(1)\n",
        "    return d"
      ],
      "metadata": {
        "id": "LqjDfQQYCzml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def _d_emb(): return 64\n",
        "\n",
        "d_emb_dict = defaultdict(_d_emb)"
      ],
      "metadata": {
        "id": "oSGL7euSjzR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NodeEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, n_nodes, d_in, d_emb, proj_nodes=None, embed_nodes=None):\n",
        "        super().__init__()\n",
        "        self.proj_nodes = proj_nodes if proj_nodes is not None else list(d_in.keys())\n",
        "        self.embed_nodes = embed_nodes if embed_nodes is not None else list(n_nodes.keys())\n",
        "        self.emb = nn.ModuleDict({k:nn.Embedding(n_nodes[k], d_emb) for k in self.embed_nodes})\n",
        "        self.proj = nn.ModuleDict({k:nn.Linear(d_in[k], d_emb, bias=False) for k in self.proj_nodes})\n",
        "        self.init()\n",
        "\n",
        "    def forward(self, nx):\n",
        "        out = {}\n",
        "        for k, m  in self.emb.items():\n",
        "            out[k] = m(nx[k])\n",
        "        for k, m  in self.proj.items():\n",
        "            out[k] = m(nx[k])\n",
        "        return out\n",
        "\n",
        "    def init(self):\n",
        "        for _, m in self.emb.items():\n",
        "            torch.nn.init.xavier_uniform_(m.weight)\n",
        "        for _, m in self.proj.items():\n",
        "            torch.nn.init.xavier_uniform_(m.weight)"
      ],
      "metadata": {
        "id": "YGqNa5UVgfio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = NodeEmbedding({k:hetero_graph.num_nodes(k) for k in [\"user\"]}, {\"article\":text_embs.shape[1]}, 64)"
      ],
      "metadata": {
        "id": "HZMUKp0Xl-8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    x = emb(hetero_graph.ndata['feat'])"
      ],
      "metadata": {
        "id": "BTV2S60Hwcut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in x.items():\n",
        "    print(k, v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPxiP5oiLFPb",
        "outputId": "6dbfc1af-d70d-4af8-8b99-ecee978615a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user torch.Size([31792, 64])\n",
            "article torch.Size([894, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as th\n",
        "from torch import nn\n",
        "\n",
        "from dgl import function as fn\n",
        "from dgl.nn.functional import edge_softmax\n",
        "from dgl.base import DGLError\n",
        "from dgl.nn.pytorch.utils import Identity\n",
        "from dgl.utils import expand_as_pair\n",
        "\n",
        "\n",
        "class GATConv(nn.Module):\n",
        "    r\"\"\"\n",
        "\n",
        "    Description\n",
        "    -----------\n",
        "    Apply `Graph Attention Network <https://arxiv.org/pdf/1710.10903.pdf>`__\n",
        "    over an input signal.\n",
        "\n",
        "    .. math::\n",
        "        h_i^{(l+1)} = \\sum_{j\\in \\mathcal{N}(i)} \\alpha_{i,j} W^{(l)} h_j^{(l)}\n",
        "\n",
        "    where :math:`\\alpha_{ij}` is the attention score bewteen node :math:`i` and\n",
        "    node :math:`j`:\n",
        "\n",
        "    .. math::\n",
        "        \\alpha_{ij}^{l} &= \\mathrm{softmax_i} (e_{ij}^{l})\n",
        "\n",
        "        e_{ij}^{l} &= \\mathrm{LeakyReLU}\\left(\\vec{a}^T [W h_{i} \\| W h_{j}]\\right)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_feats : int, or pair of ints\n",
        "        Input feature size; i.e, the number of dimensions of :math:`h_i^{(l)}`.\n",
        "        GATConv can be applied on homogeneous graph and unidirectional\n",
        "        `bipartite graph <https://docs.dgl.ai/generated/dgl.bipartite.html?highlight=bipartite>`__.\n",
        "        If the layer is to be applied to a unidirectional bipartite graph, ``in_feats``\n",
        "        specifies the input feature size on both the source and destination nodes.  If\n",
        "        a scalar is given, the source and destination node feature size would take the\n",
        "        same value.\n",
        "    out_feats : int\n",
        "        Output feature size; i.e, the number of dimensions of :math:`h_i^{(l+1)}`.\n",
        "    num_heads : int\n",
        "        Number of heads in Multi-Head Attention.\n",
        "    feat_drop : float, optional\n",
        "        Dropout rate on feature. Defaults: ``0``.\n",
        "    attn_drop : float, optional\n",
        "        Dropout rate on attention weight. Defaults: ``0``.\n",
        "    negative_slope : float, optional\n",
        "        LeakyReLU angle of negative slope. Defaults: ``0.2``.\n",
        "    residual : bool, optional\n",
        "        If True, use residual connection. Defaults: ``False``.\n",
        "    activation : callable activation function/layer or None, optional.\n",
        "        If not None, applies an activation function to the updated node features.\n",
        "        Default: ``None``.\n",
        "    allow_zero_in_degree : bool, optional\n",
        "        If there are 0-in-degree nodes in the graph, output for those nodes will be invalid\n",
        "        since no message will be passed to those nodes. This is harmful for some applications\n",
        "        causing silent performance regression. This module will raise a DGLError if it detects\n",
        "        0-in-degree nodes in input graph. By setting ``True``, it will suppress the check\n",
        "        and let the users handle it by themselves. Defaults: ``False``.\n",
        "    bias : bool, optional\n",
        "        If True, learns a bias term. Defaults: ``True``.\n",
        "\n",
        "    Note\n",
        "    ----\n",
        "    Zero in-degree nodes will lead to invalid output value. This is because no message\n",
        "    will be passed to those nodes, the aggregation function will be appied on empty input.\n",
        "    A common practice to avoid this is to add a self-loop for each node in the graph if\n",
        "    it is homogeneous, which can be achieved by:\n",
        "\n",
        "    >>> g = ... # a DGLGraph\n",
        "    >>> g = dgl.add_self_loop(g)\n",
        "\n",
        "    Calling ``add_self_loop`` will not work for some graphs, for example, heterogeneous graph\n",
        "    since the edge type can not be decided for self_loop edges. Set ``allow_zero_in_degree``\n",
        "    to ``True`` for those cases to unblock the code and handle zero-in-degree nodes manually.\n",
        "    A common practise to handle this is to filter out the nodes with zero-in-degree when use\n",
        "    after conv.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> import dgl\n",
        "    >>> import numpy as np\n",
        "    >>> import torch as th\n",
        "    >>> from dgl.nn import GATConv\n",
        "\n",
        "    >>> # Case 1: Homogeneous graph\n",
        "    >>> g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n",
        "    >>> g = dgl.add_self_loop(g)\n",
        "    >>> feat = th.ones(6, 10)\n",
        "    >>> gatconv = GATConv(10, 2, num_heads=3)\n",
        "    >>> res = gatconv(g, feat)\n",
        "    >>> res\n",
        "    tensor([[[ 3.4570,  1.8634],\n",
        "            [ 1.3805, -0.0762],\n",
        "            [ 1.0390, -1.1479]],\n",
        "            [[ 3.4570,  1.8634],\n",
        "            [ 1.3805, -0.0762],\n",
        "            [ 1.0390, -1.1479]],\n",
        "            [[ 3.4570,  1.8634],\n",
        "            [ 1.3805, -0.0762],\n",
        "            [ 1.0390, -1.1479]],\n",
        "            [[ 3.4570,  1.8634],\n",
        "            [ 1.3805, -0.0762],\n",
        "            [ 1.0390, -1.1479]],\n",
        "            [[ 3.4570,  1.8634],\n",
        "            [ 1.3805, -0.0762],\n",
        "            [ 1.0390, -1.1479]],\n",
        "            [[ 3.4570,  1.8634],\n",
        "            [ 1.3805, -0.0762],\n",
        "            [ 1.0390, -1.1479]]], grad_fn=<BinaryReduceBackward>)\n",
        "\n",
        "    >>> # Case 2: Unidirectional bipartite graph\n",
        "    >>> u = [0, 1, 0, 0, 1]\n",
        "    >>> v = [0, 1, 2, 3, 2]\n",
        "    >>> g = dgl.heterograph({('A', 'r', 'B'): (u, v)})\n",
        "    >>> u_feat = th.tensor(np.random.rand(2, 5).astype(np.float32))\n",
        "    >>> v_feat = th.tensor(np.random.rand(4, 10).astype(np.float32))\n",
        "    >>> gatconv = GATConv((5,10), 2, 3)\n",
        "    >>> res = gatconv(g, (u_feat, v_feat))\n",
        "    >>> res\n",
        "    tensor([[[-0.6066,  1.0268],\n",
        "            [-0.5945, -0.4801],\n",
        "            [ 0.1594,  0.3825]],\n",
        "            [[ 0.0268,  1.0783],\n",
        "            [ 0.5041, -1.3025],\n",
        "            [ 0.6568,  0.7048]],\n",
        "            [[-0.2688,  1.0543],\n",
        "            [-0.0315, -0.9016],\n",
        "            [ 0.3943,  0.5347]],\n",
        "            [[-0.6066,  1.0268],\n",
        "            [-0.5945, -0.4801],\n",
        "            [ 0.1594,  0.3825]]], grad_fn=<BinaryReduceBackward>)\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 in_feats,\n",
        "                 out_feats,\n",
        "                 num_heads,\n",
        "                 feat_drop=0.,\n",
        "                 attn_drop=0.,\n",
        "                 negative_slope=0.2,\n",
        "                 residual=False,\n",
        "                 activation=None,\n",
        "                 allow_zero_in_degree=False,\n",
        "                 bias=True):\n",
        "        super(GATConv, self).__init__()\n",
        "        self._num_heads = num_heads\n",
        "        self._in_src_feats, self._in_dst_feats = expand_as_pair(in_feats)\n",
        "        self._out_feats = out_feats\n",
        "        self._allow_zero_in_degree = allow_zero_in_degree\n",
        "        if isinstance(in_feats, tuple):\n",
        "            self.fc_src = nn.Linear(\n",
        "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
        "            self.fc_dst = nn.Linear(\n",
        "                self._in_dst_feats, out_feats * num_heads, bias=False)\n",
        "        else:\n",
        "            self.fc = nn.Linear(\n",
        "                self._in_src_feats, out_feats * num_heads, bias=False)\n",
        "        self.attn_l = nn.Parameter(th.FloatTensor(size=(1, num_heads, out_feats)))\n",
        "        self.attn_r = nn.Parameter(th.FloatTensor(size=(1, num_heads, out_feats)))\n",
        "        self.feat_drop = nn.Dropout(feat_drop)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(th.FloatTensor(size=(num_heads * out_feats,)))\n",
        "        else:\n",
        "            self.register_buffer('bias', None)\n",
        "        if residual:\n",
        "            if self._in_dst_feats != out_feats * num_heads:\n",
        "                self.res_fc = nn.Linear(\n",
        "                    self._in_dst_feats, num_heads * out_feats, bias=False)\n",
        "            else:\n",
        "                self.res_fc = Identity()\n",
        "        else:\n",
        "            self.register_buffer('res_fc', None)\n",
        "        self.reset_parameters()\n",
        "        self.activation = activation\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "\n",
        "        Description\n",
        "        -----------\n",
        "        Reinitialize learnable parameters.\n",
        "\n",
        "        Note\n",
        "        ----\n",
        "        The fc weights :math:`W^{(l)}` are initialized using Glorot uniform initialization.\n",
        "        The attention weights are using xavier initialization method.\n",
        "        \"\"\"\n",
        "        gain = nn.init.calculate_gain('relu')\n",
        "        if hasattr(self, 'fc'):\n",
        "            nn.init.xavier_normal_(self.fc.weight, gain=gain)\n",
        "        else:\n",
        "            nn.init.xavier_normal_(self.fc_src.weight, gain=gain)\n",
        "            nn.init.xavier_normal_(self.fc_dst.weight, gain=gain)\n",
        "        nn.init.xavier_normal_(self.attn_l, gain=gain)\n",
        "        nn.init.xavier_normal_(self.attn_r, gain=gain)\n",
        "        if self.bias is not None:\n",
        "            nn.init.constant_(self.bias, 0)\n",
        "        if isinstance(self.res_fc, nn.Linear):\n",
        "            nn.init.xavier_normal_(self.res_fc.weight, gain=gain)\n",
        "\n",
        "    def set_allow_zero_in_degree(self, set_value):\n",
        "        r\"\"\"\n",
        "\n",
        "        Description\n",
        "        -----------\n",
        "        Set allow_zero_in_degree flag.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        set_value : bool\n",
        "            The value to be set to the flag.\n",
        "        \"\"\"\n",
        "        self._allow_zero_in_degree = set_value\n",
        "\n",
        "    def forward(self, graph, feat, get_attention=False):\n",
        "        r\"\"\"\n",
        "\n",
        "        Description\n",
        "        -----------\n",
        "        Compute graph attention network layer.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        graph : DGLGraph\n",
        "            The graph.\n",
        "        feat : torch.Tensor or pair of torch.Tensor\n",
        "            If a torch.Tensor is given, the input feature of shape :math:`(N, *, D_{in})` where\n",
        "            :math:`D_{in}` is size of input feature, :math:`N` is the number of nodes.\n",
        "            If a pair of torch.Tensor is given, the pair must contain two tensors of shape\n",
        "            :math:`(N_{in}, *, D_{in_{src}})` and :math:`(N_{out}, *, D_{in_{dst}})`.\n",
        "        get_attention : bool, optional\n",
        "            Whether to return the attention values. Default to False.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The output feature of shape :math:`(N, *, H, D_{out})` where :math:`H`\n",
        "            is the number of heads, and :math:`D_{out}` is size of output feature.\n",
        "        torch.Tensor, optional\n",
        "            The attention values of shape :math:`(E, *, H, 1)`, where :math:`E` is the number of\n",
        "            edges. This is returned only when :attr:`get_attention` is ``True``.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        DGLError\n",
        "            If there are 0-in-degree nodes in the input graph, it will raise DGLError\n",
        "            since no message will be passed to those nodes. This will cause invalid output.\n",
        "            The error can be ignored by setting ``allow_zero_in_degree`` parameter to ``True``.\n",
        "        \"\"\"\n",
        "        with graph.local_scope():\n",
        "            if not self._allow_zero_in_degree:\n",
        "                if (graph.in_degrees() == 0).any():\n",
        "                    raise DGLError('There are 0-in-degree nodes in the graph, '\n",
        "                                   'output for those nodes will be invalid. '\n",
        "                                   'This is harmful for some applications, '\n",
        "                                   'causing silent performance regression. '\n",
        "                                   'Adding self-loop on the input graph by '\n",
        "                                   'calling `g = dgl.add_self_loop(g)` will resolve '\n",
        "                                   'the issue. Setting ``allow_zero_in_degree`` '\n",
        "                                   'to be `True` when constructing this module will '\n",
        "                                   'suppress the check and let the code run.')\n",
        "\n",
        "            if isinstance(feat, tuple):\n",
        "                src_prefix_shape = feat[0].shape[:-1]\n",
        "                dst_prefix_shape = feat[1].shape[:-1]\n",
        "                h_src = self.feat_drop(feat[0])\n",
        "                h_dst = self.feat_drop(feat[1])\n",
        "                if not hasattr(self, 'fc_src'):\n",
        "                    feat_src = self.fc(h_src).view(\n",
        "                        *src_prefix_shape, self._num_heads, self._out_feats)\n",
        "                    feat_dst = self.fc(h_dst).view(\n",
        "                        *dst_prefix_shape, self._num_heads, self._out_feats)\n",
        "                else:\n",
        "                    feat_src = self.fc_src(h_src).view(\n",
        "                        *src_prefix_shape, self._num_heads, self._out_feats)\n",
        "                    feat_dst = self.fc_dst(h_dst).view(\n",
        "                        *dst_prefix_shape, self._num_heads, self._out_feats)\n",
        "            else:\n",
        "                src_prefix_shape = dst_prefix_shape = feat.shape[:-1]\n",
        "                h_src = h_dst = self.feat_drop(feat)\n",
        "                feat_src = feat_dst = self.fc(h_src).view(\n",
        "                    *src_prefix_shape, self._num_heads, self._out_feats)\n",
        "                if graph.is_block:\n",
        "                    feat_dst = feat_src[:graph.number_of_dst_nodes()]\n",
        "                    h_dst = h_dst[:graph.number_of_dst_nodes()]\n",
        "                    dst_prefix_shape = (graph.number_of_dst_nodes(),) + dst_prefix_shape[1:]\n",
        "            # NOTE: GAT paper uses \"first concatenation then linear projection\"\n",
        "            # to compute attention scores, while ours is \"first projection then\n",
        "            # addition\", the two approaches are mathematically equivalent:\n",
        "            # We decompose the weight vector a mentioned in the paper into\n",
        "            # [a_l || a_r], then\n",
        "            # a^T [Wh_i || Wh_j] = a_l Wh_i + a_r Wh_j\n",
        "            # Our implementation is much efficient because we do not need to\n",
        "            # save [Wh_i || Wh_j] on edges, which is not memory-efficient. Plus,\n",
        "            # addition could be optimized with DGL's built-in function u_add_v,\n",
        "            # which further speeds up computation and saves memory footprint.\n",
        "            el = (feat_src * self.attn_l).sum(dim=-1).unsqueeze(-1)\n",
        "            er = (feat_dst * self.attn_r).sum(dim=-1).unsqueeze(-1)\n",
        "            graph.srcdata.update({'ft': feat_src, 'el': el})\n",
        "            graph.dstdata.update({'er': er})\n",
        "            # compute edge attention, el and er are a_l Wh_i and a_r Wh_j respectively.\n",
        "            graph.apply_edges(fn.u_add_v('el', 'er', 'e'))\n",
        "            e = self.leaky_relu(graph.edata.pop('e'))\n",
        "            # compute softmax\n",
        "            graph.edata['a'] = self.attn_drop(edge_softmax(graph, e))\n",
        "            # message passing\n",
        "            graph.update_all(fn.u_mul_e('ft', 'a', 'm'),\n",
        "                             fn.sum('m', 'ft'))\n",
        "            rst = graph.dstdata['ft']\n",
        "            # residual\n",
        "            if self.res_fc is not None:\n",
        "                # Use -1 rather than self._num_heads to handle broadcasting\n",
        "                resval = self.res_fc(h_dst).view(*dst_prefix_shape, self._num_heads, self._out_feats)\n",
        "                rst = rst + resval\n",
        "            # bias\n",
        "            if self.bias is not None:\n",
        "                rst = rst + self.bias.view(\n",
        "                    *((1,) * len(dst_prefix_shape)), self._num_heads, self._out_feats)\n",
        "            # activation\n",
        "            if self.activation:\n",
        "                rst = self.activation(rst)\n",
        "\n",
        "            if get_attention:\n",
        "                return rst, graph.edata['a']\n",
        "            else:\n",
        "                return rst\n"
      ],
      "metadata": {
        "id": "k82o39yKiI6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GATEncoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_h, etypes, num_heads=1, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.conv1 = dgl.nn.HeteroGraphConv({\n",
        "            rel : GATConv(d_in, d_h, num_heads, dropout, dropout,\n",
        "                      residual=True, activation=nn.SELU(), \n",
        "                  ) for rel in etypes\n",
        "        })\n",
        "        self.conv2 = dgl.nn.HeteroGraphConv({\n",
        "            rel : GATConv(d_h*num_heads, d_h, num_heads, dropout, dropout,\n",
        "                      residual=True, activation=None, \n",
        "                  ) for rel in etypes\n",
        "        })\n",
        "\n",
        "    def forward(self, graph, x):\n",
        "        x = flatten_dict(self.conv1(graph, x))\n",
        "        x = flatten_dict(self.conv2(graph, x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "VFx3l8mOsuke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hetero_graph.etypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD2XRKbc1y05",
        "outputId": "8ece3114-9ccc-4884-8d74-d3be29db0298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tweeted-by', 'follow', 'followed-by', 'tweet']"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc = GATEncoder(64, 64, hetero_graph.etypes)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = enc(hetero_graph, x)\n",
        "\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qTEeMWt1NUq",
        "outputId": "a6b3b628-f6c9-44d9-cdbb-2e7b4f520010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article': tensor([[ -0.3266,  -0.1038,   0.5618,  ...,   0.4009,   0.1296,  -0.5952],\n",
              "         [ -0.4580,   0.0000,   0.7422,  ...,   0.6925,   0.2199,  -0.6376],\n",
              "         [ -0.4343,  -0.2204,   0.0000,  ...,   0.3569,   0.1222,  -0.3507],\n",
              "         ...,\n",
              "         [  0.1897,   0.0000,  -0.7964,  ...,  -0.3503,  -0.3299,   0.2973],\n",
              "         [ -0.3282,  -0.2300,   0.5708,  ...,   0.4786,   0.2101,  -0.3290],\n",
              "         [-12.0255,   3.7374,  12.9729,  ...,   5.3041,  10.3260,   1.5975]]),\n",
              " 'user': tensor([[ -7.2155,   7.6744,  -8.2647,  ..., -20.2857,  59.6293,  29.0458],\n",
              "         [ -0.4352,  -9.0474, -13.5770,  ...,   8.4836,   1.3013, -38.1259],\n",
              "         [ -0.5463,  -8.7641, -13.9313,  ...,   8.5986,   1.5491, -38.2353],\n",
              "         ...,\n",
              "         [  1.9327,   9.0553,  16.0887,  ...,   9.9675,   5.9753,  15.6539],\n",
              "         [  1.7392,   8.9214,  16.1832,  ...,   9.8050,   5.8482,  15.7382],\n",
              "         [  1.8573,   9.1020,  15.9386,  ...,  10.2020,   5.8472,  15.6696]])}"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HetGNN(nn.Module):\n",
        "\n",
        "    def __init__(self, g, n_nodes, d_feats, d_emb, d_h, tgt_ntype, num_heads=1):\n",
        "        super().__init__()\n",
        "        self.tgt_ntype = tgt_ntype\n",
        "        self.emb = NodeEmbedding(n_nodes, d_feats, d_emb)\n",
        "        self.encoder = GATEncoder(d_emb, d_h, g.etypes, num_heads)\n",
        "        self.head = nn.Linear(d_h*num_heads, 2)\n",
        "\n",
        "    def forward(self, graph, x):\n",
        "        h = self.emb(x)\n",
        "        h = self.encoder(graph, h)\n",
        "        return self.head(h[self.tgt_ntype])"
      ],
      "metadata": {
        "id": "QKkjZgvfzZbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HetGNN(hetero_graph, {k:hetero_graph.num_nodes(k) for k in [\"user\"]}, {'article':text_embs.shape[1]}, 64, 64, \"article\")"
      ],
      "metadata": {
        "id": "aY0DeDcd3jy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    x = hetero_graph.ndata['feat']\n",
        "    logits = model(hetero_graph, x)\n",
        "\n",
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz8m3W6l4S6J",
        "outputId": "899b27d1-8351-4c7f-b2b4-5ed52e5812e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0963,  0.0365],\n",
              "        [-0.1045,  0.0137],\n",
              "        [-0.0582, -0.0235],\n",
              "        ...,\n",
              "        [-0.1146,  0.1215],\n",
              "        [-0.1310, -0.2164],\n",
              "        [ 1.8734, 11.6708]])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(logits, labels):\n",
        "    return (logits.argmax(-1) == labels).float().mean()"
      ],
      "metadata": {
        "id": "BunQmwFY8Xso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HetGNN(hetero_graph, {k:hetero_graph.num_nodes(k) for k in [\"user\"]}, {'article':text_embs.shape[1]}, 64, 64, \"article\")\n",
        "\n",
        "x = hetero_graph.ndata['feat']\n",
        "train_mask = hetero_graph.ndata['train_mask']['article']\n",
        "labels = hetero_graph.ndata['label']['article']"
      ],
      "metadata": {
        "id": "yvbuuvi556U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    logits = model(hetero_graph, x)\n",
        "\n",
        "    print(logits)\n",
        "    \n",
        "    loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "    acc = accuracy(logits[train_mask], labels[train_mask])*100\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_loss = F.cross_entropy(logits[~train_mask], labels[~train_mask])\n",
        "        val_acc = accuracy(logits[~train_mask], labels[~train_mask])*100\n",
        "    print(f\"{epoch+1:>2}: Train loss {loss.item():.4f}, acc {acc:.2f}%; validation loss {val_loss.item():.4f}, acc {val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiu8dH-42Xay",
        "outputId": "aa0c33ca-399b-4806-ed75-5dabea79913e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2874, -0.3603],\n",
            "        [-0.4980, -0.8707],\n",
            "        [-0.1554, -0.5768],\n",
            "        ...,\n",
            "        [ 0.1294,  0.3665],\n",
            "        [-0.2618, -0.4451],\n",
            "        [ 4.5736,  0.2186]], grad_fn=<AddmmBackward0>)\n",
            " 1: Train loss 1.2515, acc 84.13%; validation loss 0.9299, acc 86.26%\n",
            "tensor([[ -0.2401,  -0.2760],\n",
            "        [  0.2363,  -1.2636],\n",
            "        [ -0.0862,  -0.8869],\n",
            "        ...,\n",
            "        [ -0.1976,   0.6902],\n",
            "        [ -0.0295,  -0.4517],\n",
            "        [-15.1066,  25.2293]], grad_fn=<AddmmBackward0>)\n",
            " 2: Train loss 0.3669, acc 94.38%; validation loss 0.3607, acc 94.51%\n",
            "tensor([[  0.1031,  -0.9675],\n",
            "        [  0.4150,  -1.6566],\n",
            "        [  0.4670,  -0.9733],\n",
            "        ...,\n",
            "        [ -0.6938,   0.6817],\n",
            "        [  0.2941,  -0.6591],\n",
            "        [-42.2921,  56.4076]], grad_fn=<AddmmBackward0>)\n",
            " 3: Train loss 0.2540, acc 94.94%; validation loss 0.2636, acc 94.51%\n",
            "tensor([[  0.5598,  -1.4951],\n",
            "        [  0.9858,  -2.2431],\n",
            "        [  0.9860,  -1.5142],\n",
            "        ...,\n",
            "        [ -0.9161,   1.2317],\n",
            "        [  0.4683,  -1.4312],\n",
            "        [-51.1611,  78.0308]], grad_fn=<AddmmBackward0>)\n",
            " 4: Train loss 0.1914, acc 96.07%; validation loss 0.1959, acc 94.51%\n",
            "tensor([[  0.9486,  -1.4858],\n",
            "        [  1.4217,  -2.4783],\n",
            "        [  1.3151,  -2.0440],\n",
            "        ...,\n",
            "        [ -1.3425,   1.6388],\n",
            "        [  0.9802,  -1.5067],\n",
            "        [-34.4852,  45.9914]], grad_fn=<AddmmBackward0>)\n",
            " 5: Train loss 0.1569, acc 95.79%; validation loss 0.1669, acc 95.05%\n",
            "tensor([[  0.9214,  -2.0059],\n",
            "        [  1.3010,  -2.3176],\n",
            "        [  1.2381,  -2.4322],\n",
            "        ...,\n",
            "        [ -1.5235,   1.6835],\n",
            "        [  1.4326,  -2.2024],\n",
            "        [-93.3208, 120.1333]], grad_fn=<AddmmBackward0>)\n",
            " 6: Train loss 0.1351, acc 95.65%; validation loss 0.1435, acc 95.05%\n",
            "tensor([[  1.0561,  -2.1625],\n",
            "        [  1.9742,  -2.5982],\n",
            "        [  2.0300,  -3.0272],\n",
            "        ...,\n",
            "        [ -1.2893,   2.1207],\n",
            "        [  1.1947,  -1.6325],\n",
            "        [-55.6052,  76.0516]], grad_fn=<AddmmBackward0>)\n",
            " 7: Train loss 0.1236, acc 95.79%; validation loss 0.1365, acc 95.05%\n",
            "tensor([[   1.4272,   -2.1653],\n",
            "        [   1.7882,   -3.2086],\n",
            "        [   1.9254,   -2.9921],\n",
            "        ...,\n",
            "        [  -2.1482,    1.8538],\n",
            "        [   1.6274,   -2.7324],\n",
            "        [-128.7219,  154.1974]], grad_fn=<AddmmBackward0>)\n",
            " 8: Train loss 0.1163, acc 95.79%; validation loss 0.1293, acc 93.96%\n",
            "tensor([[   1.6045,   -2.0736],\n",
            "        [   1.8247,   -3.0902],\n",
            "        [   2.3313,   -3.0079],\n",
            "        ...,\n",
            "        [  -2.2156,    2.6536],\n",
            "        [   1.7397,   -2.8192],\n",
            "        [-183.7207,  209.2574]], grad_fn=<AddmmBackward0>)\n",
            " 9: Train loss 0.1086, acc 95.93%; validation loss 0.1247, acc 93.96%\n",
            "tensor([[   1.2229,   -1.8596],\n",
            "        [   1.9043,   -2.5316],\n",
            "        [   2.2962,   -3.3103],\n",
            "        ...,\n",
            "        [  -2.0322,    2.2654],\n",
            "        [   1.8822,   -2.7735],\n",
            "        [-133.3876,  157.0548]], grad_fn=<AddmmBackward0>)\n",
            "10: Train loss 0.1058, acc 95.65%; validation loss 0.1213, acc 93.96%\n",
            "tensor([[   1.6510,   -2.1628],\n",
            "        [   2.2677,   -3.5076],\n",
            "        [   2.8942,   -3.9428],\n",
            "        ...,\n",
            "        [  -2.5602,    2.8621],\n",
            "        [   1.6585,   -2.2539],\n",
            "        [-147.2499,  169.1334]], grad_fn=<AddmmBackward0>)\n",
            "11: Train loss 0.1047, acc 95.93%; validation loss 0.1227, acc 93.96%\n",
            "tensor([[   1.5021,   -2.8089],\n",
            "        [   2.8802,   -3.8554],\n",
            "        [   2.6092,   -3.8681],\n",
            "        ...,\n",
            "        [  -2.4934,    2.4708],\n",
            "        [   1.8405,   -2.7406],\n",
            "        [-244.5584,  275.5790]], grad_fn=<AddmmBackward0>)\n",
            "12: Train loss 0.0981, acc 96.21%; validation loss 0.1244, acc 94.51%\n",
            "tensor([[   1.9815,   -2.8007],\n",
            "        [   3.1358,   -4.0933],\n",
            "        [   3.3075,   -3.7348],\n",
            "        ...,\n",
            "        [  -2.5605,    2.5084],\n",
            "        [   2.0348,   -3.3928],\n",
            "        [-191.6037,  231.9718]], grad_fn=<AddmmBackward0>)\n",
            "13: Train loss 0.0962, acc 96.49%; validation loss 0.1331, acc 93.96%\n",
            "tensor([[   2.1802,   -2.7417],\n",
            "        [   3.0758,   -3.8003],\n",
            "        [   3.2132,   -3.9493],\n",
            "        ...,\n",
            "        [  -3.1859,    3.0314],\n",
            "        [   2.7329,   -3.9156],\n",
            "        [-232.7158,  299.0608]], grad_fn=<AddmmBackward0>)\n",
            "14: Train loss 0.0932, acc 96.77%; validation loss 0.1310, acc 93.96%\n",
            "tensor([[   2.0198,   -2.7654],\n",
            "        [   3.0177,   -4.0977],\n",
            "        [   3.2579,   -4.2271],\n",
            "        ...,\n",
            "        [  -2.6945,    2.5294],\n",
            "        [   2.7973,   -3.5521],\n",
            "        [-279.9800,  338.2866]], grad_fn=<AddmmBackward0>)\n",
            "15: Train loss 0.0911, acc 96.77%; validation loss 0.1391, acc 93.96%\n",
            "tensor([[  2.3522,  -3.1235],\n",
            "        [  3.6969,  -4.3842],\n",
            "        [  3.0382,  -4.0093],\n",
            "        ...,\n",
            "        [ -2.3231,   2.8664],\n",
            "        [  2.3910,  -3.4312],\n",
            "        [-28.5684,  35.3557]], grad_fn=<AddmmBackward0>)\n",
            "16: Train loss 0.0868, acc 97.05%; validation loss 0.1413, acc 94.51%\n",
            "tensor([[   2.3260,   -3.3008],\n",
            "        [   3.3477,   -4.1481],\n",
            "        [   2.6173,   -4.6052],\n",
            "        ...,\n",
            "        [  -3.3674,    3.1687],\n",
            "        [   2.8272,   -3.1627],\n",
            "        [-240.3981,  260.4127]], grad_fn=<AddmmBackward0>)\n",
            "17: Train loss 0.0821, acc 96.91%; validation loss 0.1541, acc 94.51%\n",
            "tensor([[   1.9515,   -2.8469],\n",
            "        [   3.1454,   -4.1132],\n",
            "        [   3.7104,   -4.8630],\n",
            "        ...,\n",
            "        [  -2.9720,    3.1337],\n",
            "        [   2.0930,   -3.0259],\n",
            "        [-271.1260,  322.3648]], grad_fn=<AddmmBackward0>)\n",
            "18: Train loss 0.0804, acc 97.33%; validation loss 0.1433, acc 95.05%\n",
            "tensor([[   2.6224,   -3.6014],\n",
            "        [   3.9044,   -4.9599],\n",
            "        [   2.9822,   -3.2083],\n",
            "        ...,\n",
            "        [  -3.3337,    3.2401],\n",
            "        [   3.0181,   -4.0092],\n",
            "        [-258.0001,  308.4138]], grad_fn=<AddmmBackward0>)\n",
            "19: Train loss 0.0762, acc 97.05%; validation loss 0.1558, acc 93.96%\n",
            "tensor([[   2.2022,   -3.2318],\n",
            "        [   3.5229,   -5.1706],\n",
            "        [   3.0191,   -3.1618],\n",
            "        ...,\n",
            "        [  -2.6186,    3.6509],\n",
            "        [   2.8798,   -3.6697],\n",
            "        [-269.2566,  298.9719]], grad_fn=<AddmmBackward0>)\n",
            "20: Train loss 0.0730, acc 97.33%; validation loss 0.1567, acc 93.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = pd.DataFrame(text_embs)"
      ],
      "metadata": {
        "id": "J3G9DxAdFyiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_data\n"
      ],
      "metadata": {
        "id": "_tVEa3L9CmE0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ecb4effd-18f9-4787-ab65-bebead622c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0          1        0.1        1.1     0.1.1     1.1.1         2  \\\n",
              "0     2.304911  -2.593269   2.804225  -2.284072 -0.005148  0.119410 -0.002614   \n",
              "1     3.648591  -3.850141   4.940054  -4.574084  0.003329  0.073702  0.013172   \n",
              "2     3.361981  -3.548838   2.995287  -2.522358 -0.002448  0.007355  0.009388   \n",
              "3     2.504427  -3.042817   2.997637  -2.761740  0.088057  0.066452  0.037585   \n",
              "4    -4.903805   5.116224  -3.947925   4.467043 -0.005155  0.097338  0.004930   \n",
              "..         ...        ...        ...        ...       ...       ...       ...   \n",
              "889   4.191693  -4.286413   3.577387  -3.207390 -0.023371  0.092738  0.007361   \n",
              "890   3.160366  -3.602673   3.074439  -2.675382  0.023739  0.075171  0.006070   \n",
              "891  -3.076209   3.358016  -1.825760   2.256844 -0.010513  0.048753  0.028684   \n",
              "892   2.994384  -2.754756   3.456599  -3.052860  0.024099  0.128845 -0.017875   \n",
              "893 -34.898632  34.124060 -62.266293  62.019722  0.010217  0.085520  0.038988   \n",
              "\n",
              "            3         4         5  ...       758       759       760  \\\n",
              "0    0.019297  0.081178  0.025727  ...  0.012692  0.059102  0.000541   \n",
              "1   -0.012052 -0.019934  0.022083  ... -0.017646  0.061697  0.007149   \n",
              "2    0.053711 -0.023324  0.000288  ...  0.039987  0.010057 -0.038091   \n",
              "3   -0.013241  0.014072  0.023239  ... -0.070302 -0.045334  0.016006   \n",
              "4   -0.013134 -0.012577 -0.004790  ...  0.007845  0.069599 -0.017022   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "889 -0.019501  0.010361  0.021039  ... -0.026921  0.033994  0.025864   \n",
              "890 -0.067172  0.016169  0.024615  ...  0.092023 -0.017697  0.014944   \n",
              "891  0.000889 -0.043573  0.023155  ... -0.050173  0.037019 -0.048023   \n",
              "892  0.012632 -0.030615 -0.001186  ... -0.008388  0.008983 -0.058522   \n",
              "893 -0.019996  0.000146  0.023523  ...  0.025953  0.049041 -0.015561   \n",
              "\n",
              "          761       762       763       764       765       766       767  \n",
              "0    0.006523 -0.018735  0.046029 -0.031323  0.021993 -0.059348  0.010890  \n",
              "1    0.000070  0.010949  0.033709 -0.033934 -0.006214 -0.046594 -0.020140  \n",
              "2   -0.033632 -0.018176 -0.017782  0.028502  0.009641 -0.035604 -0.009934  \n",
              "3    0.018444  0.056975  0.053900  0.043913  0.003843 -0.038083  0.000696  \n",
              "4    0.010712 -0.014984 -0.001413 -0.022211 -0.025620  0.007522 -0.037539  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "889 -0.034472  0.024374 -0.022076 -0.001890  0.006269 -0.019845  0.016206  \n",
              "890 -0.065511  0.016395  0.007684 -0.016207 -0.008501  0.049251 -0.022232  \n",
              "891  0.000220 -0.033158  0.075531  0.064022 -0.000590 -0.031904 -0.002240  \n",
              "892 -0.008533 -0.016264  0.003724 -0.005826 -0.020846 -0.027097 -0.008377  \n",
              "893 -0.064802  0.025398  0.007854 -0.010056  0.026847 -0.055978 -0.010197  \n",
              "\n",
              "[894 rows x 772 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbc914ff-71bb-4c78-bb50-b9d7324cee35\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>0.1</th>\n",
              "      <th>1.1</th>\n",
              "      <th>0.1.1</th>\n",
              "      <th>1.1.1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.304911</td>\n",
              "      <td>-2.593269</td>\n",
              "      <td>2.804225</td>\n",
              "      <td>-2.284072</td>\n",
              "      <td>-0.005148</td>\n",
              "      <td>0.119410</td>\n",
              "      <td>-0.002614</td>\n",
              "      <td>0.019297</td>\n",
              "      <td>0.081178</td>\n",
              "      <td>0.025727</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012692</td>\n",
              "      <td>0.059102</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.006523</td>\n",
              "      <td>-0.018735</td>\n",
              "      <td>0.046029</td>\n",
              "      <td>-0.031323</td>\n",
              "      <td>0.021993</td>\n",
              "      <td>-0.059348</td>\n",
              "      <td>0.010890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.648591</td>\n",
              "      <td>-3.850141</td>\n",
              "      <td>4.940054</td>\n",
              "      <td>-4.574084</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>0.073702</td>\n",
              "      <td>0.013172</td>\n",
              "      <td>-0.012052</td>\n",
              "      <td>-0.019934</td>\n",
              "      <td>0.022083</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.017646</td>\n",
              "      <td>0.061697</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.010949</td>\n",
              "      <td>0.033709</td>\n",
              "      <td>-0.033934</td>\n",
              "      <td>-0.006214</td>\n",
              "      <td>-0.046594</td>\n",
              "      <td>-0.020140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.361981</td>\n",
              "      <td>-3.548838</td>\n",
              "      <td>2.995287</td>\n",
              "      <td>-2.522358</td>\n",
              "      <td>-0.002448</td>\n",
              "      <td>0.007355</td>\n",
              "      <td>0.009388</td>\n",
              "      <td>0.053711</td>\n",
              "      <td>-0.023324</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039987</td>\n",
              "      <td>0.010057</td>\n",
              "      <td>-0.038091</td>\n",
              "      <td>-0.033632</td>\n",
              "      <td>-0.018176</td>\n",
              "      <td>-0.017782</td>\n",
              "      <td>0.028502</td>\n",
              "      <td>0.009641</td>\n",
              "      <td>-0.035604</td>\n",
              "      <td>-0.009934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.504427</td>\n",
              "      <td>-3.042817</td>\n",
              "      <td>2.997637</td>\n",
              "      <td>-2.761740</td>\n",
              "      <td>0.088057</td>\n",
              "      <td>0.066452</td>\n",
              "      <td>0.037585</td>\n",
              "      <td>-0.013241</td>\n",
              "      <td>0.014072</td>\n",
              "      <td>0.023239</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.070302</td>\n",
              "      <td>-0.045334</td>\n",
              "      <td>0.016006</td>\n",
              "      <td>0.018444</td>\n",
              "      <td>0.056975</td>\n",
              "      <td>0.053900</td>\n",
              "      <td>0.043913</td>\n",
              "      <td>0.003843</td>\n",
              "      <td>-0.038083</td>\n",
              "      <td>0.000696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4.903805</td>\n",
              "      <td>5.116224</td>\n",
              "      <td>-3.947925</td>\n",
              "      <td>4.467043</td>\n",
              "      <td>-0.005155</td>\n",
              "      <td>0.097338</td>\n",
              "      <td>0.004930</td>\n",
              "      <td>-0.013134</td>\n",
              "      <td>-0.012577</td>\n",
              "      <td>-0.004790</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007845</td>\n",
              "      <td>0.069599</td>\n",
              "      <td>-0.017022</td>\n",
              "      <td>0.010712</td>\n",
              "      <td>-0.014984</td>\n",
              "      <td>-0.001413</td>\n",
              "      <td>-0.022211</td>\n",
              "      <td>-0.025620</td>\n",
              "      <td>0.007522</td>\n",
              "      <td>-0.037539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>4.191693</td>\n",
              "      <td>-4.286413</td>\n",
              "      <td>3.577387</td>\n",
              "      <td>-3.207390</td>\n",
              "      <td>-0.023371</td>\n",
              "      <td>0.092738</td>\n",
              "      <td>0.007361</td>\n",
              "      <td>-0.019501</td>\n",
              "      <td>0.010361</td>\n",
              "      <td>0.021039</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026921</td>\n",
              "      <td>0.033994</td>\n",
              "      <td>0.025864</td>\n",
              "      <td>-0.034472</td>\n",
              "      <td>0.024374</td>\n",
              "      <td>-0.022076</td>\n",
              "      <td>-0.001890</td>\n",
              "      <td>0.006269</td>\n",
              "      <td>-0.019845</td>\n",
              "      <td>0.016206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>3.160366</td>\n",
              "      <td>-3.602673</td>\n",
              "      <td>3.074439</td>\n",
              "      <td>-2.675382</td>\n",
              "      <td>0.023739</td>\n",
              "      <td>0.075171</td>\n",
              "      <td>0.006070</td>\n",
              "      <td>-0.067172</td>\n",
              "      <td>0.016169</td>\n",
              "      <td>0.024615</td>\n",
              "      <td>...</td>\n",
              "      <td>0.092023</td>\n",
              "      <td>-0.017697</td>\n",
              "      <td>0.014944</td>\n",
              "      <td>-0.065511</td>\n",
              "      <td>0.016395</td>\n",
              "      <td>0.007684</td>\n",
              "      <td>-0.016207</td>\n",
              "      <td>-0.008501</td>\n",
              "      <td>0.049251</td>\n",
              "      <td>-0.022232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>-3.076209</td>\n",
              "      <td>3.358016</td>\n",
              "      <td>-1.825760</td>\n",
              "      <td>2.256844</td>\n",
              "      <td>-0.010513</td>\n",
              "      <td>0.048753</td>\n",
              "      <td>0.028684</td>\n",
              "      <td>0.000889</td>\n",
              "      <td>-0.043573</td>\n",
              "      <td>0.023155</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.050173</td>\n",
              "      <td>0.037019</td>\n",
              "      <td>-0.048023</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>-0.033158</td>\n",
              "      <td>0.075531</td>\n",
              "      <td>0.064022</td>\n",
              "      <td>-0.000590</td>\n",
              "      <td>-0.031904</td>\n",
              "      <td>-0.002240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>2.994384</td>\n",
              "      <td>-2.754756</td>\n",
              "      <td>3.456599</td>\n",
              "      <td>-3.052860</td>\n",
              "      <td>0.024099</td>\n",
              "      <td>0.128845</td>\n",
              "      <td>-0.017875</td>\n",
              "      <td>0.012632</td>\n",
              "      <td>-0.030615</td>\n",
              "      <td>-0.001186</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008388</td>\n",
              "      <td>0.008983</td>\n",
              "      <td>-0.058522</td>\n",
              "      <td>-0.008533</td>\n",
              "      <td>-0.016264</td>\n",
              "      <td>0.003724</td>\n",
              "      <td>-0.005826</td>\n",
              "      <td>-0.020846</td>\n",
              "      <td>-0.027097</td>\n",
              "      <td>-0.008377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>-34.898632</td>\n",
              "      <td>34.124060</td>\n",
              "      <td>-62.266293</td>\n",
              "      <td>62.019722</td>\n",
              "      <td>0.010217</td>\n",
              "      <td>0.085520</td>\n",
              "      <td>0.038988</td>\n",
              "      <td>-0.019996</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.023523</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025953</td>\n",
              "      <td>0.049041</td>\n",
              "      <td>-0.015561</td>\n",
              "      <td>-0.064802</td>\n",
              "      <td>0.025398</td>\n",
              "      <td>0.007854</td>\n",
              "      <td>-0.010056</td>\n",
              "      <td>0.026847</td>\n",
              "      <td>-0.055978</td>\n",
              "      <td>-0.010197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>894 rows  772 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbc914ff-71bb-4c78-bb50-b9d7324cee35')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbc914ff-71bb-4c78-bb50-b9d7324cee35 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbc914ff-71bb-4c78-bb50-b9d7324cee35');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = pd.DataFrame(logits.detach().numpy())"
      ],
      "metadata": {
        "id": "kPUollGIGOZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([my_tensor,my_data],axis=1)"
      ],
      "metadata": {
        "id": "xB1C9nIbGus4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wH_ulxSqHQCh",
        "outputId": "693a190c-9e23-480e-be9f-586bf7c49d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0           1          0          1        0.1        1.1  \\\n",
              "0      2.202197   -3.231779   2.304911  -2.593269   2.804225  -2.284072   \n",
              "1      3.522924   -5.170597   3.648591  -3.850141   4.940054  -4.574084   \n",
              "2      3.019130   -3.161778   3.361981  -3.548838   2.995287  -2.522358   \n",
              "3      2.575432   -3.333760   2.504427  -3.042817   2.997637  -2.761740   \n",
              "4     -5.555932    6.784262  -4.903805   5.116224  -3.947925   4.467043   \n",
              "..          ...         ...        ...        ...        ...        ...   \n",
              "889    3.670107   -4.268828   4.191693  -4.286413   3.577387  -3.207390   \n",
              "890    2.294929   -2.837848   3.160366  -3.602673   3.074439  -2.675382   \n",
              "891   -2.618627    3.650897  -3.076209   3.358016  -1.825760   2.256844   \n",
              "892    2.879795   -3.669688   2.994384  -2.754756   3.456599  -3.052860   \n",
              "893 -269.256592  298.971924 -34.898632  34.124060 -62.266293  62.019722   \n",
              "\n",
              "        0.1.1     1.1.1         2         3  ...       758       759  \\\n",
              "0   -0.005148  0.119410 -0.002614  0.019297  ...  0.012692  0.059102   \n",
              "1    0.003329  0.073702  0.013172 -0.012052  ... -0.017646  0.061697   \n",
              "2   -0.002448  0.007355  0.009388  0.053711  ...  0.039987  0.010057   \n",
              "3    0.088057  0.066452  0.037585 -0.013241  ... -0.070302 -0.045334   \n",
              "4   -0.005155  0.097338  0.004930 -0.013134  ...  0.007845  0.069599   \n",
              "..        ...       ...       ...       ...  ...       ...       ...   \n",
              "889 -0.023371  0.092738  0.007361 -0.019501  ... -0.026921  0.033994   \n",
              "890  0.023739  0.075171  0.006070 -0.067172  ...  0.092023 -0.017697   \n",
              "891 -0.010513  0.048753  0.028684  0.000889  ... -0.050173  0.037019   \n",
              "892  0.024099  0.128845 -0.017875  0.012632  ... -0.008388  0.008983   \n",
              "893  0.010217  0.085520  0.038988 -0.019996  ...  0.025953  0.049041   \n",
              "\n",
              "          760       761       762       763       764       765       766  \\\n",
              "0    0.000541  0.006523 -0.018735  0.046029 -0.031323  0.021993 -0.059348   \n",
              "1    0.007149  0.000070  0.010949  0.033709 -0.033934 -0.006214 -0.046594   \n",
              "2   -0.038091 -0.033632 -0.018176 -0.017782  0.028502  0.009641 -0.035604   \n",
              "3    0.016006  0.018444  0.056975  0.053900  0.043913  0.003843 -0.038083   \n",
              "4   -0.017022  0.010712 -0.014984 -0.001413 -0.022211 -0.025620  0.007522   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "889  0.025864 -0.034472  0.024374 -0.022076 -0.001890  0.006269 -0.019845   \n",
              "890  0.014944 -0.065511  0.016395  0.007684 -0.016207 -0.008501  0.049251   \n",
              "891 -0.048023  0.000220 -0.033158  0.075531  0.064022 -0.000590 -0.031904   \n",
              "892 -0.058522 -0.008533 -0.016264  0.003724 -0.005826 -0.020846 -0.027097   \n",
              "893 -0.015561 -0.064802  0.025398  0.007854 -0.010056  0.026847 -0.055978   \n",
              "\n",
              "          767  \n",
              "0    0.010890  \n",
              "1   -0.020140  \n",
              "2   -0.009934  \n",
              "3    0.000696  \n",
              "4   -0.037539  \n",
              "..        ...  \n",
              "889  0.016206  \n",
              "890 -0.022232  \n",
              "891 -0.002240  \n",
              "892 -0.008377  \n",
              "893 -0.010197  \n",
              "\n",
              "[894 rows x 774 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffa9ecaf-f3af-4d43-8394-9faf0dca8326\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>0.1</th>\n",
              "      <th>1.1</th>\n",
              "      <th>0.1.1</th>\n",
              "      <th>1.1.1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.202197</td>\n",
              "      <td>-3.231779</td>\n",
              "      <td>2.304911</td>\n",
              "      <td>-2.593269</td>\n",
              "      <td>2.804225</td>\n",
              "      <td>-2.284072</td>\n",
              "      <td>-0.005148</td>\n",
              "      <td>0.119410</td>\n",
              "      <td>-0.002614</td>\n",
              "      <td>0.019297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012692</td>\n",
              "      <td>0.059102</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.006523</td>\n",
              "      <td>-0.018735</td>\n",
              "      <td>0.046029</td>\n",
              "      <td>-0.031323</td>\n",
              "      <td>0.021993</td>\n",
              "      <td>-0.059348</td>\n",
              "      <td>0.010890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.522924</td>\n",
              "      <td>-5.170597</td>\n",
              "      <td>3.648591</td>\n",
              "      <td>-3.850141</td>\n",
              "      <td>4.940054</td>\n",
              "      <td>-4.574084</td>\n",
              "      <td>0.003329</td>\n",
              "      <td>0.073702</td>\n",
              "      <td>0.013172</td>\n",
              "      <td>-0.012052</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.017646</td>\n",
              "      <td>0.061697</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.010949</td>\n",
              "      <td>0.033709</td>\n",
              "      <td>-0.033934</td>\n",
              "      <td>-0.006214</td>\n",
              "      <td>-0.046594</td>\n",
              "      <td>-0.020140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.019130</td>\n",
              "      <td>-3.161778</td>\n",
              "      <td>3.361981</td>\n",
              "      <td>-3.548838</td>\n",
              "      <td>2.995287</td>\n",
              "      <td>-2.522358</td>\n",
              "      <td>-0.002448</td>\n",
              "      <td>0.007355</td>\n",
              "      <td>0.009388</td>\n",
              "      <td>0.053711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039987</td>\n",
              "      <td>0.010057</td>\n",
              "      <td>-0.038091</td>\n",
              "      <td>-0.033632</td>\n",
              "      <td>-0.018176</td>\n",
              "      <td>-0.017782</td>\n",
              "      <td>0.028502</td>\n",
              "      <td>0.009641</td>\n",
              "      <td>-0.035604</td>\n",
              "      <td>-0.009934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.575432</td>\n",
              "      <td>-3.333760</td>\n",
              "      <td>2.504427</td>\n",
              "      <td>-3.042817</td>\n",
              "      <td>2.997637</td>\n",
              "      <td>-2.761740</td>\n",
              "      <td>0.088057</td>\n",
              "      <td>0.066452</td>\n",
              "      <td>0.037585</td>\n",
              "      <td>-0.013241</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.070302</td>\n",
              "      <td>-0.045334</td>\n",
              "      <td>0.016006</td>\n",
              "      <td>0.018444</td>\n",
              "      <td>0.056975</td>\n",
              "      <td>0.053900</td>\n",
              "      <td>0.043913</td>\n",
              "      <td>0.003843</td>\n",
              "      <td>-0.038083</td>\n",
              "      <td>0.000696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-5.555932</td>\n",
              "      <td>6.784262</td>\n",
              "      <td>-4.903805</td>\n",
              "      <td>5.116224</td>\n",
              "      <td>-3.947925</td>\n",
              "      <td>4.467043</td>\n",
              "      <td>-0.005155</td>\n",
              "      <td>0.097338</td>\n",
              "      <td>0.004930</td>\n",
              "      <td>-0.013134</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007845</td>\n",
              "      <td>0.069599</td>\n",
              "      <td>-0.017022</td>\n",
              "      <td>0.010712</td>\n",
              "      <td>-0.014984</td>\n",
              "      <td>-0.001413</td>\n",
              "      <td>-0.022211</td>\n",
              "      <td>-0.025620</td>\n",
              "      <td>0.007522</td>\n",
              "      <td>-0.037539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>3.670107</td>\n",
              "      <td>-4.268828</td>\n",
              "      <td>4.191693</td>\n",
              "      <td>-4.286413</td>\n",
              "      <td>3.577387</td>\n",
              "      <td>-3.207390</td>\n",
              "      <td>-0.023371</td>\n",
              "      <td>0.092738</td>\n",
              "      <td>0.007361</td>\n",
              "      <td>-0.019501</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026921</td>\n",
              "      <td>0.033994</td>\n",
              "      <td>0.025864</td>\n",
              "      <td>-0.034472</td>\n",
              "      <td>0.024374</td>\n",
              "      <td>-0.022076</td>\n",
              "      <td>-0.001890</td>\n",
              "      <td>0.006269</td>\n",
              "      <td>-0.019845</td>\n",
              "      <td>0.016206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>2.294929</td>\n",
              "      <td>-2.837848</td>\n",
              "      <td>3.160366</td>\n",
              "      <td>-3.602673</td>\n",
              "      <td>3.074439</td>\n",
              "      <td>-2.675382</td>\n",
              "      <td>0.023739</td>\n",
              "      <td>0.075171</td>\n",
              "      <td>0.006070</td>\n",
              "      <td>-0.067172</td>\n",
              "      <td>...</td>\n",
              "      <td>0.092023</td>\n",
              "      <td>-0.017697</td>\n",
              "      <td>0.014944</td>\n",
              "      <td>-0.065511</td>\n",
              "      <td>0.016395</td>\n",
              "      <td>0.007684</td>\n",
              "      <td>-0.016207</td>\n",
              "      <td>-0.008501</td>\n",
              "      <td>0.049251</td>\n",
              "      <td>-0.022232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>-2.618627</td>\n",
              "      <td>3.650897</td>\n",
              "      <td>-3.076209</td>\n",
              "      <td>3.358016</td>\n",
              "      <td>-1.825760</td>\n",
              "      <td>2.256844</td>\n",
              "      <td>-0.010513</td>\n",
              "      <td>0.048753</td>\n",
              "      <td>0.028684</td>\n",
              "      <td>0.000889</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.050173</td>\n",
              "      <td>0.037019</td>\n",
              "      <td>-0.048023</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>-0.033158</td>\n",
              "      <td>0.075531</td>\n",
              "      <td>0.064022</td>\n",
              "      <td>-0.000590</td>\n",
              "      <td>-0.031904</td>\n",
              "      <td>-0.002240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>2.879795</td>\n",
              "      <td>-3.669688</td>\n",
              "      <td>2.994384</td>\n",
              "      <td>-2.754756</td>\n",
              "      <td>3.456599</td>\n",
              "      <td>-3.052860</td>\n",
              "      <td>0.024099</td>\n",
              "      <td>0.128845</td>\n",
              "      <td>-0.017875</td>\n",
              "      <td>0.012632</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008388</td>\n",
              "      <td>0.008983</td>\n",
              "      <td>-0.058522</td>\n",
              "      <td>-0.008533</td>\n",
              "      <td>-0.016264</td>\n",
              "      <td>0.003724</td>\n",
              "      <td>-0.005826</td>\n",
              "      <td>-0.020846</td>\n",
              "      <td>-0.027097</td>\n",
              "      <td>-0.008377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>-269.256592</td>\n",
              "      <td>298.971924</td>\n",
              "      <td>-34.898632</td>\n",
              "      <td>34.124060</td>\n",
              "      <td>-62.266293</td>\n",
              "      <td>62.019722</td>\n",
              "      <td>0.010217</td>\n",
              "      <td>0.085520</td>\n",
              "      <td>0.038988</td>\n",
              "      <td>-0.019996</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025953</td>\n",
              "      <td>0.049041</td>\n",
              "      <td>-0.015561</td>\n",
              "      <td>-0.064802</td>\n",
              "      <td>0.025398</td>\n",
              "      <td>0.007854</td>\n",
              "      <td>-0.010056</td>\n",
              "      <td>0.026847</td>\n",
              "      <td>-0.055978</td>\n",
              "      <td>-0.010197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>894 rows  774 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffa9ecaf-f3af-4d43-8394-9faf0dca8326')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffa9ecaf-f3af-4d43-8394-9faf0dca8326 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffa9ecaf-f3af-4d43-8394-9faf0dca8326');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('updatedEmbs.csv')"
      ],
      "metadata": {
        "id": "-eN1WO9hHRGq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}